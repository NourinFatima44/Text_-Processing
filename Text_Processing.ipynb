{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jHu9vw4XOJh3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SDTqDfuXJqp"
      },
      "source": [
        " BBC Sports Dataset(Text processing) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5CJFAHNXR9e"
      },
      "source": [
        "#1- Loading file into drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMUG16DRSH0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89802248-dc97-4159-9cda-5a69b7cdbd05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzuxncC6XeSM"
      },
      "source": [
        "##1.2 Making test and train directories for all the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOU4Nb7TO9O4"
      },
      "source": [
        "import os\n",
        "#PLEASE CHANGE THE PATH BEFORE EXECUTING\n",
        "base_dir = \"/content/drive/My Drive/bbc/\"\n",
        "root_dir = \"/content/drive/My Drive/bbc/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8J95lDYfanT"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC9wJOSFgaga"
      },
      "source": [
        "# import splitfolders  # or import split_folders\n",
        "\n",
        "# Split val/test with a fixed number of items e.g. 100 for each set.\n",
        "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
        "#splitfolders.fixed(base_dir, output=root_dir, seed=1337, fixed=(20, 20), group_prefix=None) # default values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOL34WXPT5mA"
      },
      "source": [
        "train_dir = os.path.join(root_dir,'train')\n",
        "val_dir= os.path.join(root_dir,'val')\n",
        "test_dir = os.path.join(root_dir,'test')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJTgqL_8_ZZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90712470-96f3-48f3-b481-cf2c7aff7b58"
      },
      "source": [
        "os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sport', 'entertainment', 'tech', 'politics', 'business']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDljG8I5f6Oa"
      },
      "source": [
        "#2- Preprocessing on Text data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHh3nhp8hrgP"
      },
      "source": [
        "##2.1- Laoding data from folders and assigning them labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0YcOTxMhxcV"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "train_data = load_files(train_dir)\n",
        "xi_train, yi_train = train_data.data, train_data.target\n",
        "val_data = load_files(val_dir)\n",
        "xi_val, yi_val = val_data.data, val_data.target\n",
        "test_data = load_files(test_dir)\n",
        "xi_test, yi_test = test_data.data, test_data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a6GeB6i6pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbe4327-887c-4896-e1ed-3da966d4362a"
      },
      "source": [
        "xi_test[1:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b\"A question of trust and technology\\n\\nA major government department is without e-mail for a week, and technology analyst Bill Thompson wants to know what happened.\\n\\nA couple of weeks ago I wrote about how my girlfriend had suffered when her cable modem blew up and she was offline for several days. It seems that thousands of civil servants at the UK's Department of Work and Pensions went through the same thing last week. It has emerged that the internal network crashed in a particularly horrible way, depriving staff of e-mail and access to the application software they use to calculate people's benefit and pension entitlement or note changes in personal circumstances. Senior consultants from EDS, the computer firm which manage the system, and Microsoft, which supplied the software, were running around trying to figure out what had to be done to fix it all, while staff resorted to phone, fax and probably carrier pigeon to get work done. Fortunately the back-office systems which actually pay people their money were still working, so only new claims and updates were affected done properly. This is bad enough for those affected, but it does mean that the impact is not devastating for millions of pensioners. I am sure regular readers will be expecting one of my usual diatribes against poor software, badly specified systems and inadequate disaster recovery plans.\\n\\nAlthough the full story has not yet been told, it seems that the problem started when a plan to upgrade some of the computers from Windows 2000 to Windows XP went wrong, and XP code was inadvertently copied to thousands of machines across the network.\\n\\nThis is certainly unfortunate, but I have a lot of sympathy for the network managers and technology staff involved. Today's computer networks are large, complex and occasionally fragile. The interconnectedness that we all value also gives us a degree of instability and unpredictability that we cannot design out of the systems. It is the network equivalent of Godel's Theorem - any system sufficiently complex to be useful is also able to collapse catastrophically. So I will reserve judgment on the technology aspects until we all know what actually happened and whether it was a consequence of software failure or just bad luck. What is really disturbing, and cannot be excused, is the fact that it took four days for news of this systems failure to leak out into the technical press.\\n\\nIt is, without a doubt, a major story and was the second or third lead item on BBC Radio 4's Today programme throughout Friday morning.\\n\\nSo why did not the prime minister's official spokesman mention it at any lobby briefings before Friday? Why was not the pensions minister in Parliament to make an emergency statement on Tuesday, when it was clear that there was a serious problem? If there had been an outbreak of Legionnaire's disease in the air conditioning system we would have been told, but it seems that major technology problems do not merit the same treatment. While EDS and Microsoft will no doubt be looking for technical lessons to learn from their week of pain, we can learn some political lessons too. And the most important is that in this digital world, technology failures are matters of public interest, not something that can be ignored in the hope that nobody will notice, care or understand. That means we need a full report on what went wrong and what was done to fix it. It would be unacceptable for any of the parties involved to hide behind commercial confidentiality or even parliamentary privilege. A major system has evidently collapsed and we need to know what went wrong and what is being done differently. Anything less is a betrayal of public trust.\\n\\nBill Thompson is a regular commentator on the BBC World Service programme Go Digital.\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNpCz8J5o4Sa"
      },
      "source": [
        "##2.2- Data cleaning by NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W4XN93go_bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72843df2-ea02-418c-b81e-740a2c4de7fd"
      },
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocessing(X):\n",
        "  documents = []\n",
        "  stemmer = WordNetLemmatizer()\n",
        "  \n",
        "  for sen in range(0, len(X)):\n",
        "      # Remove all the special characters\n",
        "      document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "      # remove all single characters\n",
        "      document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "      # Remove single characters from the start\n",
        "      document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "      # Remove next line \n",
        "      document = re.sub('\\n', '', document)\n",
        "\n",
        "      # Substituting multiple spaces with single space\n",
        "      document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "      # Removing prefixed 'b'\n",
        "      document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "      # Converting to Lowercase\n",
        "      document = document.lower()\n",
        "    \n",
        "      # Lemmatization\n",
        "      document = document.split()\n",
        "\n",
        "      document = [stemmer.lemmatize(word) for word in document]\n",
        "      document = ' '.join(document)\n",
        "\n",
        "      documents.append(document)\n",
        "  return documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIS3CMtGqH-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38eae6ff-c104-4f1c-c846-dc0ba508e850"
      },
      "source": [
        "nltk.download('omw-1.4')\n",
        "xc_train = preprocessing(xi_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_u7QWkLsjqU"
      },
      "source": [
        "xc_val = preprocessing(xi_val)\n",
        "xc_test = preprocessing(xi_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDr4M24Mt-qQ"
      },
      "source": [
        "##2.3- Printing Values before and after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJu6moAXr904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81b3212-1949-4427-a0f9-4ce9bd93e950"
      },
      "source": [
        "print('-'*50)\n",
        "print('Before applying Preprocessing tasks')\n",
        "print('-'*50)\n",
        "print(xi_train[5:10])\n",
        "\n",
        "print()\n",
        "print('-'*50)\n",
        "print('After Removing Stopwords Function')\n",
        "print('-'*50)\n",
        "print(xc_train[5:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Before applying Preprocessing tasks\n",
            "--------------------------------------------------\n",
            "[b'SEC to rethink post-Enron rules\\n\\nThe US stock market watchdog\\'s chairman has said he is willing to soften tough new US corporate governance rules to ease the burden on foreign firms.\\n\\nIn a speech at the London School of Economics, William Donaldson promised \"several initiatives\". European firms have protested that US laws introduced after the Enron scandal make Wall Street listings too costly. The US regulator said foreign firms may get extra time to comply with a key clause in the Sarbanes-Oxley Act.\\n\\nThe Act comes into force in mid-2005. It obliges all firms with US stock market listings to make declarations, which, critics say, will add substantially to the cost of preparing their annual accounts.\\n\\nFirms that break the new law could face huge fines, while senior executives risk jail terms of up to 20 years. Mr Donaldson said that although the Act does not provide exemptions for foreign firms, the Securities and Exchange Commission (SEC) would \"continue to be sensitive to the need to accomodate foreign structures and requirements\". There are few, if any, who disagree with the intentions of the Act, which obliges chief executives to sign a statement taking responsibility for the accuracy of the accounts. But European firms with secondary listings in New York have objected - arguing that the compliance costs outweigh the benefits of a dual listing. The Act also applies to firms with more than 300 US shareholders, a situation many firms without US listings could find themselves in.\\n\\nThe 300-shareholder threshold has drawn anger as it effectively blocks the most obvious remedy, a delisting. Mr Donaldson said the SEC would \"consider whether there should be a new approach to the deregistration process\" for foreign firms unwilling to meet US requirements.\\n\\n\"We should seek a solution that will preserve investor protections\" without turning the US market into \"one with no exit\", he said. He revealed that his staff were already weighing up the merits of delaying the implementation of the Act\\'s least popular measure - Section 404 - for foreign firms. Seen as particularly costly to implement, Section 404 obliges chief executives to take responsibility for the firm\\'s internal controls by signing a compliance statement in the annual accounts. The SEC has already delayed implementation of this clause for smaller firms - including US ones - with market capitalisations below $700m (\\xc2\\xa3374m).\\n\\nA delegation of European firms visited the SEC in December to press for change, the Financial Times reported.\\n\\nIt was led by Digby Jones, director general of the UK\\'s Confederation of British Industry (CBI) and included representatives of BASF, Siemens and Cadbury Schweppes. Compliance costs are already believed to be making firms wary of US listings. Air China picked the London Stock Exchange for its secondary listing in its $1.07bn (\\xc2\\xa3558m) stock market debut last month. There are also rumours that two Chinese state-run banks - China Construction Bank and Bank of China - have abandoned plans for multi-billion dollar listings in New York later this year. Instead, the cost of Sarbanes-Oxley has persuaded them to stick to a single listing in Hong Kong, according to press reports in China.\\n', b'Voters \\'don\\'t trust politicians\\'\\n\\nEight out of 10 voters do not trust politicians to tell the truth, a new poll conducted for the BBC suggests.\\n\\nAnd 87% of the 1,000 adults quizzed by ICM for BBC News 24 said politicians did not deliver what they promised. The poll comes after Foreign Secretary Jack Straw predicted trust would be \"the key choice\" at the next election. Both the Tories and the Lib Dems are keen to emphasise a perceived lack of trust in Tony Blair, following his claims over Iraqi weapons.\\n\\nBut according to the BBC poll, 61% said the issue of trust made no difference to whether or not they would vote at the next election, widely expected on 5 May. The poll also looked at what lay behind the lack of trust in politicians. Some 87% said politicians did not keep the promises they made before elections, while 92% said they never gave \"a straight answer\". Just under three-quarters of respondents (73%) said politicians had shown themselves to be dishonest too often.\\n\\nMr Straw told activists in Blackburn on Thursday that voters would have to decide at the next election which party \"best deserves\" their \"future trust\". \"That in the end is the key choice at the next election.\"\\n\\nHe acknowledged that the public had lost faith in Labour, but suggested it could persuade people to \"reinvest their trust with us\" if the party could overcome Tory attempts to spread cynicism in politics. The Conservatives are keen to highlight the trust issue. During his response to Gordon Brown\\'s Budget statement on Tuesday, Michael Howard compared the chancellor\\'s figures to the prime minister\\'s claims about Iraq\\'s weapons of mass destruction.\\n\\nThe Lib Dems are also keen to highlight the trust issue, with Charles Kennedy has claiming voters had a \"fundamental lack of trust in the prime minister\". And the Green Party unveiled a billboard opposite the Palace of Westminster accusing the government of lying over the Iraq war.\\n\\nFormer education secretary Estelle Morris told BBC News 24 that there was a \"real problem of trust\" between the public and the politicians. She said she did not feel her own colleagues could be trusted, but suggested the \"three-cornered relationship\" between the press, politicians and the public had a hand in the issue. The public was often turned off by sitting on the sidelines in \"the battle of words\" between the politician and the journalist, she added. Lib Dem foreign affairs spokesman Menzies Campbell said the Iraq war had hit trust in politicians hard. \"Issues of war and peace, life and death do have a very damaging effect on the credibility of politicians\". Martin Bell, who won the Tatton seat from Tory Neil Hamilton on anti-corruption platform, said politicians often failed to see themselves as others did. \"We need public figures we trust to tell the truth and who can see themselves as others see them.\"\\n', b\"Hague's six-figure earnings shown\\n\\nThe rewards of leaving front-bench politics are shown in the latest annual register of members' interests.\\n\\nThe register shows former Tory leader William Hague earning up to \\xc2\\xa3820,000 on top of his MPs' salary, much of it from speaking fees. His former shadow chancellor Michael Portillo makes up to \\xc2\\xa3560,000 a year - partly because of speeches and TV work. Ex-health secretary Alan Milburn earned up to \\xc2\\xa385,000 from speeches, articles and advice while not in the Cabinet.\\n\\nMr Milburn was away from the frontbench for just more than a year between stepping down as health secretary and becoming Labour's election supremo. His declared interests include \\xc2\\xa320,000 from newspaper articles and fees of up to \\xc2\\xa335,000 for four speeches. He also commanded a salary of between \\xc2\\xa325,000 and \\xc2\\xa335,000 for being on investment company Bridgepoint Capital's European advisory committee. His time out of office will, however, have lost him his \\xc2\\xa371,433 minister's salary. Mr Hague's work outside Parliament included two one-man shows, which with other speaking fees netted him up to \\xc2\\xa3480,000. He also earned up to \\xc2\\xa3195,000 for a weekly column in the News of the World, and between \\xc2\\xa35,000 and \\xc2\\xa310,000 for presenting BBC'2's Have I Got News for You. Mr Hague was also paid an undisclosed amount for the newspaper serialisation of his biography of William Pitt the Younger and up to \\xc2\\xa3135,00 for work as an adviser to various companies.\\n\\nFormer Defence Secretary Michael Portillo makes some of his money as a non-executive director of BAE Systems. He is to stand down as an MP at the next election. And former Foreign Secretary Robin Cook was paid between \\xc2\\xa345,001 and \\xc2\\xa350,000 for the paperback edition of his book about his resignation from government. His declared income of up to \\xc2\\xa3205,000 also includes payments for being a consultant to the Tote and for his regular column in the Guardian newspaper. The register also shows former Home Office Minister Ann Widdecombe declaring a \\xc2\\xa3100,000 advance for her third and fourth novels. She also received up to \\xc2\\xa330,000 for acting as the Guardian's agony aunt and between \\xc2\\xa35,001 and \\xc2\\xa310,000 for appearing on ITV's Celebrity Fit Club. David Blunkett has become a paid adviser to Indepen Consulting Limited now he is not home secretary - he helps them with seminars about the relationship between government and business. He earns between \\xc2\\xa35,001and \\xc2\\xa310,000 for the work.\\n\\nTony Blair's entry confirms that King Abdullah of Jordan paid for him to fly from a holiday in Egypt to official discussions - and for a sightseeing tour to Wadi Rum. Tory leader Michael Howard's only fresh entry is a Christmas hamper from the Sultan of Brunei. He also declares a trip to Mexico last year to address executives of News International, and helicopter and private jet travel paid for by supporters. Liberal Democrat leader Charles Kennedy registered donations to his office from supporters, a free ticket to last year's Bafta awards and rent from a single-bedroom flat in London. The register only contains new information for December 2004 - but Monday saw the publication of the annual review of the register, with the year's details. The payments are shown in bands of up \\xc2\\xa35,000, making it difficult to calculate the exact earnings.\\n\", b\"DVD review: Harry Potter and the Prisoner of Azkaban\\n\\nThis third Harry Potter film brought a change of director and a dramatic visual shake-up that really shines on DVD.\\n\\nGone are the warm, bright colours found in the two earlier films, Alfonso Cuaron brings in a bleak and cold feel that is simply gorgeous - and looks even better here than in the cinema. It is all part of the progression of Harry's story into darker areas, but you'll spend time just marvelling at the beautiful Hogwarts landscape.\\n\\nThis is the first Potter film where you get so lost in the screen adaptation that you forget the book. It is the third year at Hogwarts and studies are interrupted, as they always are, by a calamity that only Harry, Ron and Hermione can put right.\\n\\nIt sounds corny. But Harry is no longer the winsome hero, he is a moody teenager and Daniel Radcliffe pulls it off very well. Emma Watson is ever better as Hermione, and the young stars are joined by the usual myriad famous actors including Gary Oldman and Emma Thompson. The film itself is the reason to buy this DVD. But it is laden with behind-the-scenes extras, including funny, if shallow, interviews with all the main cast. But what seems like a long list of features can be swiftly whittled down to the few that you are going to watch. Younger viewers will go for the games which include a Magic You May Have Missed memory test, and Crookshanks chasing off after Scabbers. Adult viewers will ignore those and go straight to the deleted scenes. You will understand why they were deleted but it is fun to see more footage - and not have to hunt through endless menus to find it, as we did on the first Harry Potter DVD. The most interesting pieces are an interview with JK Rowling in Creating The Vision and Conjuring A Scene, a short featurette about the making of the film's big moments.\\n\", b'GM in crunch talks on Fiat future\\n\\nFiat will meet car giant General Motors (GM) on Tuesday in an attempt to reach agreement over the future of the Italian firm\\'s loss-making auto group.\\n\\nFiat claims that GM is legally obliged to buy the 90% of the car unit it does not already own; GM says the contract, signed in 2000, is no longer valid. Press reports have speculated that Fiat may be willing to accept a cash payment in return for dropping its claim. Both companies want to cut costs as the car industry adjusts to waning demand.\\n\\nThe meeting between Fiat boss Sergio Marchionne and GM\\'s Rick Wagoner is due to take place at 1330 GMT in Zurich, according to the Reuters news agency.\\n\\nMr Marchionne is confident of his firm\\'s legal position, saying in an interview with the Financial Times that GM\\'s argument \"has no legs\". The agreement in question dates back to GM\\'s decision to buy 20% of Fiat\\'s auto division in 2000. At the time, it gave the Italian firm the right, via a \\'put option\\', to sell the remaining stake to GM. In recent weeks, Fiat has reiterated its claims that this \\'put\\' is still valid and legally binding. However, GM argues that a Fiat share sale made last year, which cut GM\\'s holding to 10%, together with asset sales made by Fiat have terminated the agreement.\\n\\nSelling the Fiat\\'s car-making unit may not prove so simple, analysts say, especially as it is a company that is so closely linked to Italy\\'s industrial heritage. Political and public pressure may well push the two firms to reach a compromise. \"We are not expecting Fiat to exercise its put of the auto business against an unwilling GM at this point,\" brokerage Merrill Lynch said in a note to investors, adding that any legal battle would be protracted and damaging to the business. \"As far as we are aware, the Agnelli family, which indirectly controls at least 30% of Fiat, has not given a firm public indication that it wants to sell the auto business. \"Fiat may be willing to cancel the \\'put\\' in exchange for money.\"\\n']\n",
            "\n",
            "--------------------------------------------------\n",
            "After Removing Stopwords Function\n",
            "--------------------------------------------------\n",
            "['sec to rethink post enron rule nthe u stock market watchdog chairman ha said he is willing to soften tough new u corporate governance rule to ease the burden on foreign firm nin speech at the london school of economics william donaldson promised several initiative european firm have protested that u law introduced after the enron scandal make wall street listing too costly the u regulator said foreign firm may get extra time to comply with key clause in the sarbanes oxley act nthe act come into force in mid 2005 it obliges all firm with u stock market listing to make declaration which critic say will add substantially to the cost of preparing their annual account nfirms that break the new law could face huge fine while senior executive risk jail term of up to 20 year mr donaldson said that although the act doe not provide exemption for foreign firm the security and exchange commission sec would continue to be sensitive to the need to accomodate foreign structure and requirement there are few if any who disagree with the intention of the act which obliges chief executive to sign statement taking responsibility for the accuracy of the account but european firm with secondary listing in new york have objected arguing that the compliance cost outweigh the benefit of dual listing the act also applies to firm with more than 300 u shareholder situation many firm without u listing could find themselves in nthe 300 shareholder threshold ha drawn anger a it effectively block the most obvious remedy delisting mr donaldson said the sec would consider whether there should be new approach to the deregistration process for foreign firm unwilling to meet u requirement n we should seek solution that will preserve investor protection without turning the u market into one with no exit he said he revealed that his staff were already weighing up the merit of delaying the implementation of the act least popular measure section 404 for foreign firm seen a particularly costly to implement section 404 obliges chief executive to take responsibility for the firm internal control by signing compliance statement in the annual account the sec ha already delayed implementation of this clause for smaller firm including u one with market capitalisation below 700m xc2 xa3374m na delegation of european firm visited the sec in december to press for change the financial time reported nit wa led by digby jones director general of the uk confederation of british industry cbi and included representative of basf siemens and cadbury schweppes compliance cost are already believed to be making firm wary of u listing air china picked the london stock exchange for it secondary listing in it 1 07bn xc2 xa3558m stock market debut last month there are also rumour that two chinese state run bank china construction bank and bank of china have abandoned plan for multi billion dollar listing in new york later this year instead the cost of sarbanes oxley ha persuaded them to stick to single listing in hong kong according to press report in china', 'voter don trust politician neight out of 10 voter do not trust politician to tell the truth new poll conducted for the bbc suggests nand 87 of the 1 000 adult quizzed by icm for bbc news 24 said politician did not deliver what they promised the poll come after foreign secretary jack straw predicted trust would be the key choice at the next election both the tory and the lib dems are keen to emphasise perceived lack of trust in tony blair following his claim over iraqi weapon nbut according to the bbc poll 61 said the issue of trust made no difference to whether or not they would vote at the next election widely expected on 5 may the poll also looked at what lay behind the lack of trust in politician some 87 said politician did not keep the promise they made before election while 92 said they never gave straight answer just under three quarter of respondent 73 said politician had shown themselves to be dishonest too often nmr straw told activist in blackburn on thursday that voter would have to decide at the next election which party best deserves their future trust that in the end is the key choice at the next election nhe acknowledged that the public had lost faith in labour but suggested it could persuade people to reinvest their trust with u if the party could overcome tory attempt to spread cynicism in politics the conservative are keen to highlight the trust issue during his response to gordon brown budget statement on tuesday michael howard compared the chancellor figure to the prime minister claim about iraq weapon of mass destruction nthe lib dems are also keen to highlight the trust issue with charles kennedy ha claiming voter had fundamental lack of trust in the prime minister and the green party unveiled billboard opposite the palace of westminster accusing the government of lying over the iraq war nformer education secretary estelle morris told bbc news 24 that there wa real problem of trust between the public and the politician she said she did not feel her own colleague could be trusted but suggested the three cornered relationship between the press politician and the public had hand in the issue the public wa often turned off by sitting on the sideline in the battle of word between the politician and the journalist she added lib dem foreign affair spokesman menzies campbell said the iraq war had hit trust in politician hard issue of war and peace life and death do have very damaging effect on the credibility of politician martin bell who won the tatton seat from tory neil hamilton on anti corruption platform said politician often failed to see themselves a others did we need public figure we trust to tell the truth and who can see themselves a others see them', 'hague six figure earnings shown nthe reward of leaving front bench politics are shown in the latest annual register of member interest nthe register show former tory leader william hague earning up to xc2 xa3820 000 on top of his mp salary much of it from speaking fee his former shadow chancellor michael portillo make up to xc2 xa3560 000 year partly because of speech and tv work ex health secretary alan milburn earned up to xc2 xa385 000 from speech article and advice while not in the cabinet nmr milburn wa away from the frontbench for just more than year between stepping down a health secretary and becoming labour election supremo his declared interest include xc2 xa320 000 from newspaper article and fee of up to xc2 xa335 000 for four speech he also commanded salary of between xc2 xa325 000 and xc2 xa335 000 for being on investment company bridgepoint capital european advisory committee his time out of office will however have lost him his xc2 xa371 433 minister salary mr hague work outside parliament included two one man show which with other speaking fee netted him up to xc2 xa3480 000 he also earned up to xc2 xa3195 000 for weekly column in the news of the world and between xc2 xa35 000 and xc2 xa310 000 for presenting bbc 2 have got news for you mr hague wa also paid an undisclosed amount for the newspaper serialisation of his biography of william pitt the younger and up to xc2 xa3135 00 for work a an adviser to various company nformer defence secretary michael portillo make some of his money a non executive director of bae system he is to stand down a an mp at the next election and former foreign secretary robin cook wa paid between xc2 xa345 001 and xc2 xa350 000 for the paperback edition of his book about his resignation from government his declared income of up to xc2 xa3205 000 also includes payment for being consultant to the tote and for his regular column in the guardian newspaper the register also show former home office minister ann widdecombe declaring xc2 xa3100 000 advance for her third and fourth novel she also received up to xc2 xa330 000 for acting a the guardian agony aunt and between xc2 xa35 001 and xc2 xa310 000 for appearing on itv celebrity fit club david blunkett ha become paid adviser to indepen consulting limited now he is not home secretary he help them with seminar about the relationship between government and business he earns between xc2 xa35 001and xc2 xa310 000 for the work ntony blair entry confirms that king abdullah of jordan paid for him to fly from holiday in egypt to official discussion and for sightseeing tour to wadi rum tory leader michael howard only fresh entry is christmas hamper from the sultan of brunei he also declares trip to mexico last year to address executive of news international and helicopter and private jet travel paid for by supporter liberal democrat leader charles kennedy registered donation to his office from supporter free ticket to last year bafta award and rent from single bedroom flat in london the register only contains new information for december 2004 but monday saw the publication of the annual review of the register with the year detail the payment are shown in band of up xc2 xa35 000 making it difficult to calculate the exact earnings', 'dvd review harry potter and the prisoner of azkaban nthis third harry potter film brought change of director and dramatic visual shake up that really shine on dvd ngone are the warm bright colour found in the two earlier film alfonso cuaron brings in bleak and cold feel that is simply gorgeous and look even better here than in the cinema it is all part of the progression of harry story into darker area but you ll spend time just marvelling at the beautiful hogwarts landscape nthis is the first potter film where you get so lost in the screen adaptation that you forget the book it is the third year at hogwarts and study are interrupted a they always are by calamity that only harry ron and hermione can put right nit sound corny but harry is no longer the winsome hero he is moody teenager and daniel radcliffe pull it off very well emma watson is ever better a hermione and the young star are joined by the usual myriad famous actor including gary oldman and emma thompson the film itself is the reason to buy this dvd but it is laden with behind the scene extra including funny if shallow interview with all the main cast but what seems like long list of feature can be swiftly whittled down to the few that you are going to watch younger viewer will go for the game which include magic you may have missed memory test and crookshanks chasing off after scabbers adult viewer will ignore those and go straight to the deleted scene you will understand why they were deleted but it is fun to see more footage and not have to hunt through endless menu to find it a we did on the first harry potter dvd the most interesting piece are an interview with jk rowling in creating the vision and conjuring scene short featurette about the making of the film big moment', 'gm in crunch talk on fiat future nfiat will meet car giant general motor gm on tuesday in an attempt to reach agreement over the future of the italian firm loss making auto group nfiat claim that gm is legally obliged to buy the 90 of the car unit it doe not already own gm say the contract signed in 2000 is no longer valid press report have speculated that fiat may be willing to accept cash payment in return for dropping it claim both company want to cut cost a the car industry adjusts to waning demand nthe meeting between fiat bos sergio marchionne and gm rick wagoner is due to take place at 1330 gmt in zurich according to the reuters news agency nmr marchionne is confident of his firm legal position saying in an interview with the financial time that gm argument ha no leg the agreement in question date back to gm decision to buy 20 of fiat auto division in 2000 at the time it gave the italian firm the right via put option to sell the remaining stake to gm in recent week fiat ha reiterated it claim that this put is still valid and legally binding however gm argues that fiat share sale made last year which cut gm holding to 10 together with asset sale made by fiat have terminated the agreement nselling the fiat car making unit may not prove so simple analyst say especially a it is company that is so closely linked to italy industrial heritage political and public pressure may well push the two firm to reach compromise we are not expecting fiat to exercise it put of the auto business against an unwilling gm at this point brokerage merrill lynch said in note to investor adding that any legal battle would be protracted and damaging to the business a far a we are aware the agnelli family which indirectly control at least 30 of fiat ha not given firm public indication that it want to sell the auto business fiat may be willing to cancel the put in exchange for money']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtgK4K-hvYrt"
      },
      "source": [
        "##2.4- Converting the text files to vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At9nrNsZvjMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32faa0b-821a-4371-a755-2845800bade3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "max_feature = 4500\n",
        "maxlen=200\n",
        "#vectorizer = CountVectorizer(max_features=max_feature, stop_words=stopwords.words('english'))\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_feature)\n",
        "tokenizer.fit_on_texts(xc_train)\n",
        "sequences = tokenizer.texts_to_sequences(xc_train)\n",
        "x_train = pad_sequences(sequences, maxlen=maxlen)\n",
        "sequences = tokenizer.texts_to_sequences(xc_test)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "sequences = tokenizer.texts_to_sequences(xc_val)\n",
        "x_val = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2025, 200)\n",
            "(100, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eauh4b_kwpwA"
      },
      "source": [
        "#x_train = vectorizer.fit_transform(xc_train).toarray()\n",
        "#x_test = vectorizer.fit_transform(xc_test).toarray()\n",
        "#x_val = vectorizer.fit_transform(xc_val).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMPDmld0wPlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671ef0d9-120d-4639-9988-86846a5e6bb4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MMG8Ta9w0Si"
      },
      "source": [
        "##2.5- Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BLTZthTw6bB"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train = labelencoder.fit_transform(yi_train)\n",
        "y_test = labelencoder.fit_transform(yi_test)\n",
        "y_val = labelencoder.fit_transform(yi_val)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-80cBklrxwdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888f3332-b912-4d17-ca37-6a11db5649e4"
      },
      "source": [
        "print('the shape of training data')\n",
        "print('-'*40)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print()\n",
        "\n",
        "print('the shape of validation data')\n",
        "print('-'*40)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "print()\n",
        "\n",
        "print('the shape of test data')\n",
        "print('-'*40)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of training data\n",
            "----------------------------------------\n",
            "(2025, 200)\n",
            "(2025, 5)\n",
            "\n",
            "the shape of validation data\n",
            "----------------------------------------\n",
            "(100, 200)\n",
            "(100, 5)\n",
            "\n",
            "the shape of test data\n",
            "----------------------------------------\n",
            "(100, 200)\n",
            "(100, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDKEr0q0zoYq"
      },
      "source": [
        "#Task1 Fully Connected Dense NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RyoKbOT0TIw"
      },
      "source": [
        "##1 training model on 10 epochs and reporting accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db2KJvrSzmmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d866907-6553-4978-81b3-62bcb0d61f69"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "dnn = models.Sequential()\n",
        "dnn.add(layers.Dense(128, activation = 'relu', input_shape=(x_train.shape[1],)))\n",
        "dnn.add(layers.Dense(64, activation = 'relu'))\n",
        "dnn.add(layers.Dense(32, activation = 'relu'))\n",
        "dnn.add(layers.Dense(16, activation = 'relu'))\n",
        "dnn.add(layers.Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "dnn.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "          \n",
        "\n",
        "history = dnn.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 3s 10ms/step - loss: 79.4535 - accuracy: 0.1916 - val_loss: 2.9207 - val_accuracy: 0.2100\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2.2486 - accuracy: 0.2207 - val_loss: 1.6099 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1.6676 - accuracy: 0.2336 - val_loss: 1.5954 - val_accuracy: 0.1700\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.6294 - accuracy: 0.2331 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.6012 - accuracy: 0.2356 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.5974 - accuracy: 0.2356 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.6679 - accuracy: 0.2370 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.5968 - accuracy: 0.2356 - val_loss: 1.6135 - val_accuracy: 0.2000\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.6583 - accuracy: 0.2311 - val_loss: 1.6142 - val_accuracy: 0.2000\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1.5997 - accuracy: 0.2356 - val_loss: 1.6146 - val_accuracy: 0.2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRpYcz7Z5W6J"
      },
      "source": [
        "##2 Plotting traning and val accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZREcAE0q_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7739b73c-2167-4f42-f4f9-647e256497ef"
      },
      "source": [
        "for key in history.history.keys():\n",
        "    print(key)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "accuracy\n",
            "val_loss\n",
            "val_accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkHnyWAd5i2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c86531d2-c194-4d7c-f2ef-60c0ddd627cb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc= history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbgW1Emv6DeZ"
      },
      "source": [
        "##3- Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umcbYYwc6BUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b962af-4a0e-43eb-e4b8-c179786774ad"
      },
      "source": [
        "test_loss, test_acc = dnn.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6065 - accuracy: 0.2000\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.20000000298023224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0Ji8g8BtZ-"
      },
      "source": [
        "#Task2- Using Word Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miw6JD-L_ifJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ea8583-0796-4407-c91e-f471324e6624"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "#maxlen = 120\n",
        "max_feature =4500\n",
        "emb_dim = 200\n",
        "\n",
        "\n",
        "\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=maxlen)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iey462UCVnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917991b5-cdac-4b49-e9f1-2da5ea26f999"
      },
      "source": [
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers import Embedding\n",
        "\n",
        "enn = models.Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "enn.add(Embedding(max_feature, emb_dim, input_length=maxlen))\n",
        "enn.add(Flatten())\n",
        "enn.add(layers.Dense(128, activation = 'relu'))\n",
        "enn.add(layers.Dense(64, activation = 'relu'))\n",
        "enn.add(layers.Dense(32, activation = 'relu'))\n",
        "enn.add(layers.Dense(16, activation = 'relu'))\n",
        "enn.add(layers.Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "enn.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = enn.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 1s 10ms/step - loss: 1.1348 - accuracy: 0.5427 - val_loss: 0.5510 - val_accuracy: 0.7900\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9812 - val_loss: 0.3239 - val_accuracy: 0.8400\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 7.6980e-05 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.8900\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 3.9901e-06 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 2.7433e-07 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.8900\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 2.9964e-08 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8800\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 5.4159e-09 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 2.6491e-09 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9000\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 1.8838e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.8800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4xjK45atHlQ"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AI1X1MRtHlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9896c0d9-c21a-4868-abda-172ee48d5f2e"
      },
      "source": [
        "test_loss, test_acc = enn.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.8900\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.8899999856948853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNwP2EP22XtG"
      },
      "source": [
        "#Task3- Using Glove Embedding With Dense Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCtSrLdw6KbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977030cd-a155-4548-eab1-89c60fa97660"
      },
      "source": [
        "glove_path = '/content/drive/MyDrive/glove.6B.100d.txt'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(glove_path)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huz-ouyb2XtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f561f40c-9d78-4a3d-db87-be0252cd841f"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras import preprocessing\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "tokenizer = Tokenizer(num_words=max_feature)\n",
        "tokenizer.fit_on_texts(xc_train)\n",
        "sequences = tokenizer.texts_to_sequences(xc_train)\n",
        "word_index = tokenizer.word_index\n",
        "#print('Found %s unique tokens.' % len(word_index))\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "embedding_matrix = np.zeros((max_feature, emb_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_feature:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE5Yii302XtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3175c13c-5fb5-45b2-8d22-2c67ec508734"
      },
      "source": [
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers import Embedding\n",
        "\n",
        "gnn = models.Sequential()\n",
        "# We specify the maximum input length to our Embedding layer\n",
        "# so we can later flatten the embedded inputs\n",
        "gnn.add(Embedding(max_feature, emb_dim, input_length=maxlen))\n",
        "gnn.add(Flatten())\n",
        "gnn.add(layers.Dense(128, activation = 'relu'))\n",
        "gnn.add(layers.Dense(64, activation = 'relu'))\n",
        "gnn.add(layers.Dense(32, activation = 'relu'))\n",
        "gnn.add(layers.Dense(16, activation = 'relu'))\n",
        "gnn.add(layers.Dense(5, activation = 'softmax'))\n",
        "\n",
        "gnn.layers[0].set_weights([embedding_matrix])\n",
        "gnn.layers[0].trainable = False\n",
        "\n",
        "\n",
        "gnn.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = gnn.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 1s 10ms/step - loss: 1.7568 - accuracy: 0.3812 - val_loss: 1.3903 - val_accuracy: 0.4500\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.7694 - val_loss: 0.7590 - val_accuracy: 0.7000\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8973 - val_loss: 0.5456 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9477 - val_loss: 0.1996 - val_accuracy: 0.9200\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.9407 - val_loss: 0.2989 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9798 - val_loss: 0.2723 - val_accuracy: 0.8600\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9852 - val_loss: 0.2912 - val_accuracy: 0.8900\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.2013 - val_accuracy: 0.9200\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9664 - val_loss: 0.3265 - val_accuracy: 0.8900\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 5.9764e-04 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IheAohcH2XtH"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8JGUTdm2XtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5570d9-8fa0-470f-d3d2-fb424b672388"
      },
      "source": [
        "test_loss, test_acc = gnn.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8800\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.8799999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au8Bfp369uVZ"
      },
      "source": [
        "#Task4- RNN with Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkUTBjgQ9uVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0416904-1eaf-42a4-87a3-57973aee2fe5"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22b8XjFf9uVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b46bea-77e0-41a5-a592-be7787a99458"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "\n",
        "rnn = Sequential()\n",
        "rnn.add(Embedding(4500, 64))\n",
        "rnn.add(SimpleRNN(64, return_sequences=True))\n",
        "rnn.add(SimpleRNN(32)) \n",
        "rnn.add(Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "rnn.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = rnn.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 19s 333ms/step - loss: 1.6308 - accuracy: 0.2405 - val_loss: 1.5992 - val_accuracy: 0.3100\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 16s 318ms/step - loss: 1.2236 - accuracy: 0.5679 - val_loss: 1.5796 - val_accuracy: 0.3800\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 17s 341ms/step - loss: 0.5807 - accuracy: 0.8795 - val_loss: 1.7789 - val_accuracy: 0.3100\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 18s 351ms/step - loss: 0.1685 - accuracy: 0.9852 - val_loss: 1.8967 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 16s 315ms/step - loss: 0.0414 - accuracy: 0.9990 - val_loss: 2.1041 - val_accuracy: 0.2900\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 16s 312ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.5716 - val_accuracy: 0.3100\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 18s 357ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.2900\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 16s 316ms/step - loss: 0.0371 - accuracy: 0.9906 - val_loss: 3.0329 - val_accuracy: 0.3500\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 16s 317ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9975 - val_accuracy: 0.3400\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 16s 320ms/step - loss: 2.5427e-04 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl8TgaR_9uVa"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8RLDJDL9uVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18170a18-aeec-4bdf-9525-cc3610397522"
      },
      "source": [
        "test_loss, test_acc = rnn.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 34ms/step - loss: 2.7855 - accuracy: 0.4700\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.4699999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBkJaJ0-LHzT"
      },
      "source": [
        "#Task5- RNN with Glove "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqaxAhOYLHzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e62822d-28a0-4946-a2fb-215685c522c9"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUoKgHUMLHzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0fc8af1-70c6-4113-83d7-34d0b8bd027c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "\n",
        "grnn = Sequential()\n",
        "grnn.add(Embedding(max_feature,emb_dim))\n",
        "grnn.add(SimpleRNN(64, return_sequences=True))\n",
        "grnn.add(SimpleRNN(32)) \n",
        "grnn.add(Dense(5, activation = 'softmax'))\n",
        "grnn.layers[0].set_weights([embedding_matrix])\n",
        "grnn.layers[0].trainable = False\n",
        "\n",
        "\n",
        "grnn.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = grnn.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 19s 342ms/step - loss: 1.5847 - accuracy: 0.2899 - val_loss: 1.4187 - val_accuracy: 0.3300\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 15s 303ms/step - loss: 1.1968 - accuracy: 0.5244 - val_loss: 1.0929 - val_accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 15s 303ms/step - loss: 0.9809 - accuracy: 0.6153 - val_loss: 1.3374 - val_accuracy: 0.4800\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 16s 309ms/step - loss: 0.8503 - accuracy: 0.6948 - val_loss: 1.8741 - val_accuracy: 0.3200\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 17s 336ms/step - loss: 0.7600 - accuracy: 0.7210 - val_loss: 0.9269 - val_accuracy: 0.6800\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 16s 309ms/step - loss: 0.6912 - accuracy: 0.7590 - val_loss: 0.6459 - val_accuracy: 0.8100\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 16s 306ms/step - loss: 0.7550 - accuracy: 0.7309 - val_loss: 1.4204 - val_accuracy: 0.5200\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 16s 306ms/step - loss: 0.7021 - accuracy: 0.7531 - val_loss: 0.7455 - val_accuracy: 0.7400\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 17s 335ms/step - loss: 0.6244 - accuracy: 0.7807 - val_loss: 0.7193 - val_accuracy: 0.8100\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 15s 302ms/step - loss: 0.6451 - accuracy: 0.7778 - val_loss: 0.8422 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLyNVbnGLHzV"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JReaWtNLHzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e73467-bcd4-4ff7-8a19-f5425e16d988"
      },
      "source": [
        "test_loss, test_acc = grnn.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 31ms/step - loss: 0.7066 - accuracy: 0.7500\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMewKA0MqB7"
      },
      "source": [
        "#Task6- LSTM with Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErdEGnIMqB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a1475d-71fc-42e8-e0dd-9a2453519cfd"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNSKvyfWMqB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997c895e-0f0f-4e60-c35e-d2cce0df5449"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_feature, emb_dim))\n",
        "lstm.add(LSTM(64, return_sequences=True))\n",
        "lstm.add(LSTM(32)) \n",
        "lstm.add(Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "lstm.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = lstm.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 8s 32ms/step - loss: 1.3534 - accuracy: 0.3842 - val_loss: 1.1628 - val_accuracy: 0.3900\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 1.0040 - accuracy: 0.5565 - val_loss: 0.8901 - val_accuracy: 0.6500\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.6275 - accuracy: 0.7748 - val_loss: 0.5060 - val_accuracy: 0.8700\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3903 - accuracy: 0.8998 - val_loss: 0.6187 - val_accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.2319 - accuracy: 0.9506 - val_loss: 0.5443 - val_accuracy: 0.8500\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1528 - accuracy: 0.9649 - val_loss: 0.5670 - val_accuracy: 0.8300\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0954 - accuracy: 0.9802 - val_loss: 0.6464 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0693 - accuracy: 0.9837 - val_loss: 0.5323 - val_accuracy: 0.8600\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0494 - accuracy: 0.9906 - val_loss: 0.5815 - val_accuracy: 0.8800\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0463 - accuracy: 0.9901 - val_loss: 0.5602 - val_accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTL7pV23MqB-"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNC9VlnMqB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2be357-c1f2-4883-c886-232016fecaf6"
      },
      "source": [
        "test_loss, test_acc = lstm.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.8700\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.8700000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHu9vw4XOJh3"
      },
      "source": [
        "#Task7- LSTM with Glove Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gDx4VROJh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece86e8d-b31b-4c95-d990-9eb9aaad980c"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYGKjMjJOJh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b954acc-8b10-4181-c9ed-eb511ad00d9e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "glstm = Sequential()\n",
        "glstm.add(Embedding(max_feature, emb_dim))\n",
        "glstm.add(LSTM(64, return_sequences=True))\n",
        "glstm.add(LSTM(32)) \n",
        "glstm.add(Dense(5, activation = 'softmax'))\n",
        "glstm.layers[0].set_weights([embedding_matrix])\n",
        "glstm.layers[0].trainable = False\n",
        "\n",
        "\n",
        "glstm.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = glstm.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 4s 33ms/step - loss: 1.0821 - accuracy: 0.5985 - val_loss: 0.7312 - val_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.6012 - accuracy: 0.8148 - val_loss: 0.5567 - val_accuracy: 0.8200\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.5424 - accuracy: 0.8321 - val_loss: 0.5204 - val_accuracy: 0.8500\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.3972 - accuracy: 0.8854 - val_loss: 0.4911 - val_accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.4615 - accuracy: 0.8568 - val_loss: 0.5541 - val_accuracy: 0.8100\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3377 - accuracy: 0.9052 - val_loss: 0.3288 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3581 - accuracy: 0.8993 - val_loss: 0.4296 - val_accuracy: 0.8700\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.3379 - accuracy: 0.9052 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.3007 - accuracy: 0.9067 - val_loss: 0.3772 - val_accuracy: 0.8900\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.3495 - accuracy: 0.9032 - val_loss: 0.3597 - val_accuracy: 0.8900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj1elDVsOJh4"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqV9fIWiOJh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9084f0-57d5-4845-8cd3-22d192e37f1d"
      },
      "source": [
        "test_loss, test_acc = glstm.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5169 - accuracy: 0.8400\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.8399999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uweC1Tb9QNWY"
      },
      "source": [
        "#Task8- Bi LSTM with Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJceB89DQNWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78b4a99-7dcf-4f03-d004-1c103ba4f63a"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SPEtCBVQNWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e7ba5f-3a49-4dc0-8e8d-10ba9e7e221f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "\n",
        "blstm = Sequential()\n",
        "blstm.add(Embedding(max_feature, emb_dim))\n",
        "blstm.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "blstm.add(Bidirectional(LSTM(32))) \n",
        "blstm.add(Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "blstm.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = blstm.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 10s 84ms/step - loss: 1.3430 - accuracy: 0.4084 - val_loss: 0.9921 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 2s 32ms/step - loss: 0.7031 - accuracy: 0.7175 - val_loss: 0.7621 - val_accuracy: 0.7600\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.3692 - accuracy: 0.8864 - val_loss: 0.3037 - val_accuracy: 0.9100\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.1836 - accuracy: 0.9556 - val_loss: 0.1942 - val_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.1912 - accuracy: 0.9412 - val_loss: 0.3751 - val_accuracy: 0.9200\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.1184 - val_accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.0743 - accuracy: 0.9812 - val_loss: 0.1807 - val_accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.2344 - val_accuracy: 0.9300\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 2s 31ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.2091 - val_accuracy: 0.9600\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.0976 - accuracy: 0.9817 - val_loss: 0.5509 - val_accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE0rdbhPQNWc"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rAjhcMkQNWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8587bc-0a80-4316-c66e-f0f5807ab99e"
      },
      "source": [
        "test_loss, test_acc = blstm.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5670 - accuracy: 0.8400\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.8399999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FYsIsOETa30"
      },
      "source": [
        "#Task9- BiLSTM with Glove Embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFoVJYvTTa30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2376a5b8-62d7-4a90-f34e-a9e2c01f307f"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8KHZ5cPTa31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46d48e9-869a-4b2d-8698-23d9d1bad73f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "gblstm = Sequential()\n",
        "gblstm.add(Embedding(max_feature, emb_dim))\n",
        "gblstm.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "gblstm.add(Bidirectional(LSTM(32))) \n",
        "gblstm.add(Dense(5, activation = 'softmax'))\n",
        "gblstm.layers[0].set_weights([embedding_matrix])\n",
        "gblstm.layers[0].trainable = False\n",
        "\n",
        "\n",
        "gblstm.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = gblstm.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=40,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 8s 58ms/step - loss: 0.9524 - accuracy: 0.6494 - val_loss: 0.7269 - val_accuracy: 0.7100\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.4231 - accuracy: 0.8593 - val_loss: 0.4600 - val_accuracy: 0.8200\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.3529 - accuracy: 0.8825 - val_loss: 0.7337 - val_accuracy: 0.7200\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.3086 - accuracy: 0.8978 - val_loss: 0.4489 - val_accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.2738 - accuracy: 0.9072 - val_loss: 0.4118 - val_accuracy: 0.9100\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.2381 - accuracy: 0.9220 - val_loss: 0.1826 - val_accuracy: 0.9400\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.1899 - accuracy: 0.9437 - val_loss: 0.2630 - val_accuracy: 0.8800\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 2s 30ms/step - loss: 0.2082 - accuracy: 0.9343 - val_loss: 0.2077 - val_accuracy: 0.9400\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.1671 - accuracy: 0.9422 - val_loss: 0.1656 - val_accuracy: 0.9600\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 1s 29ms/step - loss: 0.1632 - accuracy: 0.9477 - val_loss: 0.1553 - val_accuracy: 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9IoJUS6Ta31"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABA5o_sUTa31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41055ec-c5e5-4176-c25d-0b15817328e9"
      },
      "source": [
        "test_loss, test_acc = gblstm.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1930 - accuracy: 0.9300\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.9300000071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1-w-kTZVsvU"
      },
      "source": [
        "#Task10- 1D CNN with Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfn1_aOyVsvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a672e6d2-d787-452c-b3a9-69319524cab2"
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "\n",
        "# Cut texts after this number of words \n",
        "# (among top max_features most common words)\n",
        "max_feature =4500\n",
        "emb_dim = 100\n",
        "# Load the data as lists of integers.\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2025, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_iMfscMVsvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12af37b-ff4a-4821-ed0f-549645bc557c"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_feature, 128, input_length=maxlen))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(5))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train,\n",
        "                  y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=10,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 200, 128)          576000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 194, 32)           28704     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 38, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 32, 32)            7200      \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 612,069\n",
            "Trainable params: 612,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203/203 [==============================] - 6s 7ms/step - loss: 1.6440 - acc: 0.2415 - val_loss: 1.5299 - val_acc: 0.2700\n",
            "Epoch 2/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.5470 - acc: 0.3091 - val_loss: 1.5265 - val_acc: 0.2100\n",
            "Epoch 3/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.5293 - acc: 0.3748 - val_loss: 1.5261 - val_acc: 0.2100\n",
            "Epoch 4/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.5106 - acc: 0.4005 - val_loss: 1.5153 - val_acc: 0.3600\n",
            "Epoch 5/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.4913 - acc: 0.4933 - val_loss: 1.5098 - val_acc: 0.4000\n",
            "Epoch 6/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.4700 - acc: 0.5694 - val_loss: 1.4989 - val_acc: 0.3100\n",
            "Epoch 7/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.4461 - acc: 0.5812 - val_loss: 1.4784 - val_acc: 0.4100\n",
            "Epoch 8/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.4217 - acc: 0.5877 - val_loss: 1.4568 - val_acc: 0.4300\n",
            "Epoch 9/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.3960 - acc: 0.5862 - val_loss: 1.4277 - val_acc: 0.5100\n",
            "Epoch 10/10\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 1.3678 - acc: 0.5847 - val_loss: 1.3967 - val_acc: 0.5300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WbWuX1qVsvV"
      },
      "source": [
        "##Reporting test and val accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-AtoPdjVsvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3aba6b-7f8a-4180-9391-50f9697b7a87"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Testing accuracy for the model')\n",
        "print('-'*20)\n",
        "print('test acc:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 49ms/step - loss: 1.4027 - acc: 0.5100\n",
            "Testing accuracy for the model\n",
            "--------------------\n",
            "test acc: 0.5099999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXiS0uY9t5gl"
      },
      "source": [
        "#Task 12 : Reporting Accuracies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mvhhb3JzCP3"
      },
      "source": [
        "from google.colab import files \n",
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvxE_GrNzjjH"
      },
      "source": [
        "#upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aLi77S2z4M-"
      },
      "source": [
        "# Image('assignment 5 accuracies.JPG', width = 600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4HtuF40LHx"
      },
      "source": [
        "**Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g6y-Cwz2oMZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/bbc/\")\n",
        "val_dir = \"val\"\n",
        "train_dir = \"train\"\n",
        "categories = os.listdir(\"train\")\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLm1aoFfoel1",
        "outputId": "b99b79fd-36d9-4560-9401-fa84b30b8132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2025 files belonging to 5 classes.\n",
            "Found 100 files belonging to 5 classes.\n",
            "Found 100 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "xveOkmxSoPlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "jifkh_suqExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance Metrics\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "DkDXUZ0EoRra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\", f1_m, precision_m, recall_m])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"task1_a.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfH4q2_7oW7x",
        "outputId": "17ebc9cf-2c8e-4b4f-8b99-c627525b6364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_12 (Embedding)    (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " transformer_encoder_2 (Tran  (None, None, 256)        543776    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,665,061\n",
            "Trainable params: 5,665,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 6s 71ms/step - loss: 1.6988 - accuracy: 0.5007 - f1_m: 1.3552 - precision_m: 1.3434 - recall_m: 1.3841 - val_loss: 0.4954 - val_accuracy: 0.8000 - val_f1_m: 1.0409 - val_precision_m: 0.9386 - val_recall_m: 1.2115\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 5s 68ms/step - loss: 0.3921 - accuracy: 0.8642 - f1_m: 1.0097 - precision_m: 0.9171 - recall_m: 1.1314 - val_loss: 0.1561 - val_accuracy: 0.9400 - val_f1_m: 0.8747 - val_precision_m: 0.7766 - val_recall_m: 1.0283\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 4s 66ms/step - loss: 0.1603 - accuracy: 0.9496 - f1_m: 0.9168 - precision_m: 0.8166 - recall_m: 1.0513 - val_loss: 0.0654 - val_accuracy: 0.9800 - val_f1_m: 0.8806 - val_precision_m: 0.7891 - val_recall_m: 1.0000\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 6s 93ms/step - loss: 0.0606 - accuracy: 0.9812 - f1_m: 0.8890 - precision_m: 0.7913 - recall_m: 1.0216 - val_loss: 0.0881 - val_accuracy: 0.9600 - val_f1_m: 0.9327 - val_precision_m: 0.8709 - val_recall_m: 1.0100\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 6s 83ms/step - loss: 0.0366 - accuracy: 0.9891 - f1_m: 0.8834 - precision_m: 0.7843 - recall_m: 1.0178 - val_loss: 0.0613 - val_accuracy: 0.9700 - val_f1_m: 0.8940 - val_precision_m: 0.8032 - val_recall_m: 1.0104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff551a56590>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(int_test_ds)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w-1x18YqTWy",
        "outputId": "1630c057-e02e-4682-b0a2-fe1c5da2bed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 31ms/step - loss: 0.0496 - accuracy: 0.9800 - f1_m: 0.8944 - precision_m: 0.8034 - recall_m: 1.0096\n",
            "0.9800000190734863\n"
          ]
        }
      ]
    }
  ]
}